{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kinga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Kinga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Import libraries for text preprocessing\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# You only need to download these resources once. After you run this \n",
    "# the first time--or if you know you already have these installed--\n",
    "# you can comment these two lines out (with a #)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file that combines the metadata downoladed, the generated text and users data from the survey\n",
    "df = pd.read_csv(\"text-metadata-survey.csv\")\n",
    "df = df.rename(columns={'text' :\"col\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering for a specific characteristic of the users I am interested in\n",
    "df = df[df['Concerned'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=[\"col\"])\n",
    "df = df.dropna(subset=[\"col\"])\n",
    "df = df.dropna(subset=[\"video_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['language'] =='en']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "addapted from https://nicharuc.github.io/topic_modeling/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = nltk.collocations.BigramCollocationFinder.from_documents([comment.split() for comment in df.col])\n",
    "# Filter only those that occur at least 50 times\n",
    "finder.apply_freq_filter(10)\n",
    "bigram_scores = finder.score_ngrams(bigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "finder = nltk.collocations.TrigramCollocationFinder.from_documents([comment.split() for comment in df.col])\n",
    "# Filter only those that occur at least 50 times\n",
    "finder.apply_freq_filter(10)\n",
    "trigram_scores = finder.score_ngrams(trigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_pmi = pd.DataFrame(bigram_scores)\n",
    "bigram_pmi.columns = ['bigram', 'pmi']\n",
    "bigram_pmi.sort_values(by='pmi', axis = 0, ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_pmi = pd.DataFrame(trigram_scores)\n",
    "trigram_pmi.columns = ['trigram', 'pmi']\n",
    "trigram_pmi.sort_values(by='pmi', axis = 0, ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for bigrams with only noun-type structures\n",
    "def bigram_filter(bigram):\n",
    "    tag = nltk.pos_tag(bigram)\n",
    "    if tag[0][1] not in ['JJ', 'NN'] and tag[1][1] not in ['NN']:\n",
    "        return False\n",
    "    if bigram[0] in stop_word_list or bigram[1] in stop_word_list:\n",
    "        return False\n",
    "    if 'n' in bigram or 't' in bigram:\n",
    "        return False\n",
    "    if 'PRON' in bigram:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for trigrams with only noun-type structures\n",
    "def trigram_filter(trigram):\n",
    "    tag = nltk.pos_tag(trigram)\n",
    "    if tag[0][1] not in ['JJ', 'NN'] and tag[1][1] not in ['JJ','NN']:\n",
    "        return False\n",
    "    if trigram[0] in stop_word_list or trigram[-1] in stop_word_list or trigram[1] in stop_word_list:\n",
    "        return False\n",
    "    if 'n' in trigram or 't' in trigram:\n",
    "         return False\n",
    "    if 'PRON' in trigram:\n",
    "        return False\n",
    "    return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "titok_stopwords = ['fyp', \"foryou\", \"foryoupage\", \"greenscreen\", \"dlaciebie\", \"fy\", \"duet\", \"stitch\", \"reply\"]\n",
    "\n",
    "path = \"C:/Users/Kinga/Desktop/Research Master/Newsflow/Code/\"\n",
    "my_file = open(path + \"polish.stopwords.txt\", \"r\", encoding='utf-8')\n",
    "polish_stopwords = my_file.read().split('\\n')\n",
    "stop_word_list = list(set(stopwords.words(\"dutch\") + stopwords.words(\"english\") + polish_stopwords + titok_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can set pmi threshold to whatever makes sense - eyeball through and select threshold where n-grams stop making sense\n",
    "# choose top 500 ngrams in this case ranked by PMI that have noun like structures\n",
    "filtered_bigram = bigram_pmi[bigram_pmi.apply(lambda bigram:\\\n",
    "                                              bigram_filter(bigram['bigram'])\\\n",
    "                                              and bigram.pmi > 5, axis = 1)][:500]\n",
    "\n",
    "filtered_trigram = trigram_pmi[trigram_pmi.apply(lambda trigram: \\\n",
    "                                                 trigram_filter(trigram['trigram'])\\\n",
    "                                                 and trigram.pmi > 5, axis = 1)][:500]\n",
    "\n",
    "\n",
    "bigrams = [' '.join(x) for x in filtered_bigram.bigram.values if len(x[0]) > 2 or len(x[1]) > 2]\n",
    "trigrams = [' '.join(x) for x in filtered_trigram.trigram.values if len(x[0]) > 2 or len(x[1]) > 2 and len(x[2]) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate n-grams\n",
    "def replace_ngram(x):\n",
    "    for gram in trigrams:\n",
    "        x = x.replace(gram, '_'.join(gram.split()))\n",
    "    for gram in bigrams:\n",
    "        x = x.replace(gram, '_'.join(gram.split()))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = df[[\"col\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kinga\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "rl.col = rl.col.map(lambda x: replace_ngram(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process dataset to get a cleaned and normalised text corpus\n",
    "corpus = []\n",
    "df['word_count'] = rl.col.apply(lambda x: len(str(x).split(\" \")))\n",
    "ds_count = len(df['word_count'])\n",
    "for i in range(0, ds_count):\n",
    "    # Remove punctuation\n",
    "    text = re.sub('[^a-zA-Z]', ' ', str(rl.col.iloc[i]))\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove tags\n",
    "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    \n",
    "    # Remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    # Convert to list from string\n",
    "    text = text.split()\n",
    "    \n",
    "    # Stemming\n",
    "    ps=PorterStemmer()\n",
    "    \n",
    "    # Lemmatisation\n",
    "    lem = WordNetLemmatizer()\n",
    "    text = [lem.lemmatize(word) for word in text if not word in  \n",
    "            stop_word_list] \n",
    "    corpus.append(text)\n",
    "\n",
    "rl.col = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for only nouns\n",
    "def noun_only(x):\n",
    "    pos_comment = nltk.pos_tag(x)\n",
    "    filtered = [word[0] for word in pos_comment if word[1] in ['NN']]\n",
    "    # to filter both noun and verbs\n",
    "    #filtered = [word[0] for word in pos_comment if word[1] in ['NN','VB', 'VBD', 'VBG', 'VBN', 'VBZ']]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = rl.col.map(noun_only)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for d in corpus:\n",
    "    text.append(' '.join(d))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitermplus as btm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitermplus as btm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<00:00, 2314.65it/s]\n",
      "100%|██████████| 55/55 [00:00<00:00, 18384.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mariupol odessa news russianplane law russiavs...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>childhood damage</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>russian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moment everything oldcat bond</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>war height internationalwomensday christianity</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>senator kennedy embarrassment shame johnkenned...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>president zelenskiy government consider sex pa...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sound</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>plu mm year anatomy anatomylesson traditionala...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>russianinvasion slavaukraine foodinsecurity wh...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>privilege work poland europe</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>site mathiaszamecki art howtodraw artlesson pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>war ukraine</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>opinion spicy time relationshiptok intimacycoa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>spell tho</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>secretary general explosion poland tuesday lif...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>secretary general explosion poland tuesday lif...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>secretary general explosion poland tuesday lif...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>secretary general explosion poland tuesday lif...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>man fluke bl blcreator blcontent bxb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>childhood damage</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>childhood damage</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>childhood damage</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>thing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>thing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>course pt artwork draw sketch anatomy illustra...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>site mathiaszamecki art howtodraw artlesson pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>course pt artwork draw sketch anatomy illustra...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>site mathiaszamecki art howtodraw artlesson pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>course pt artwork draw sketch anatomy illustra...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>site mathiaszamecki art howtodraw artlesson pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cerebri cerebral anatomyclass scienceclass bio...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>winner war paradiseisland therumbling</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>school year realize art style characterdesign ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>poland missile strike credit calvin germany si...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>secretary general explosion poland tuesday lif...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>game balkan bulgaria croatia bosnia macedonia ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>russiastopthewar mykolaivbombedeveryday</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>missile poland article news russia poland miss...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>russiapoland russianmisslecrisis helppoland uk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>grandma russia kherson</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>c v b heart attack kpop gidle soojin ot yuqinator</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>view theaudacity</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>secretary general explosion poland tuesday lif...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>secretary general explosion poland tuesday lif...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>secretary general explosion poland tuesday lif...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>truth babe latvian</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>oldie goldie globaltiktok recommendation rec</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>regret comment humanity history anthropology h...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>dino spot tolkientok lotr ringsofpower</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>jedillwag brazil brasileirao lula putinwalk bo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ride tesla elonmusk twitterblue</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ride tesla elonmusk twitterblue</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>amazinghistory</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>treasure family truestory wwi christmas</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            documents  label\n",
       "0   mariupol odessa news russianplane law russiavs...      6\n",
       "1                                    childhood damage      3\n",
       "2                                             russian      1\n",
       "3                       moment everything oldcat bond      3\n",
       "4      war height internationalwomensday christianity      5\n",
       "5   senator kennedy embarrassment shame johnkenned...      3\n",
       "6   president zelenskiy government consider sex pa...      9\n",
       "7                                               sound      1\n",
       "8   plu mm year anatomy anatomylesson traditionala...      7\n",
       "9   russianinvasion slavaukraine foodinsecurity wh...      7\n",
       "10                       privilege work poland europe      5\n",
       "11  site mathiaszamecki art howtodraw artlesson pr...      0\n",
       "12                                        war ukraine      5\n",
       "13  opinion spicy time relationshiptok intimacycoa...      2\n",
       "14                                          spell tho      1\n",
       "15  secretary general explosion poland tuesday lif...      8\n",
       "16  secretary general explosion poland tuesday lif...      8\n",
       "17  secretary general explosion poland tuesday lif...      8\n",
       "18  secretary general explosion poland tuesday lif...      8\n",
       "19               man fluke bl blcreator blcontent bxb      0\n",
       "20                                   childhood damage      3\n",
       "21                                   childhood damage      3\n",
       "22                                   childhood damage      3\n",
       "23                                              thing      1\n",
       "24                                              thing      1\n",
       "25  course pt artwork draw sketch anatomy illustra...      6\n",
       "26  site mathiaszamecki art howtodraw artlesson pr...      0\n",
       "27  course pt artwork draw sketch anatomy illustra...      6\n",
       "28  site mathiaszamecki art howtodraw artlesson pr...      0\n",
       "29  course pt artwork draw sketch anatomy illustra...      6\n",
       "30  site mathiaszamecki art howtodraw artlesson pr...      0\n",
       "31  cerebri cerebral anatomyclass scienceclass bio...      9\n",
       "32              winner war paradiseisland therumbling      7\n",
       "33  school year realize art style characterdesign ...      0\n",
       "34  poland missile strike credit calvin germany si...      5\n",
       "35  secretary general explosion poland tuesday lif...      8\n",
       "36  game balkan bulgaria croatia bosnia macedonia ...      5\n",
       "37            russiastopthewar mykolaivbombedeveryday      3\n",
       "38  missile poland article news russia poland miss...      4\n",
       "39  russiapoland russianmisslecrisis helppoland uk...      1\n",
       "40                             grandma russia kherson      3\n",
       "41  c v b heart attack kpop gidle soojin ot yuqinator      3\n",
       "42                                   view theaudacity      7\n",
       "43  secretary general explosion poland tuesday lif...      8\n",
       "44  secretary general explosion poland tuesday lif...      8\n",
       "45  secretary general explosion poland tuesday lif...      8\n",
       "46                                 truth babe latvian      7\n",
       "47       oldie goldie globaltiktok recommendation rec      5\n",
       "48  regret comment humanity history anthropology h...      4\n",
       "49             dino spot tolkientok lotr ringsofpower      1\n",
       "50  jedillwag brazil brasileirao lula putinwalk bo...      3\n",
       "51                    ride tesla elonmusk twitterblue      5\n",
       "52                    ride tesla elonmusk twitterblue      5\n",
       "53                                     amazinghistory      1\n",
       "54            treasure family truestory wwi christmas      4"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# IMPORTING DATA\n",
    "\n",
    "texts = text\n",
    "\n",
    "# PREPROCESSING\n",
    "# Obtaining terms frequency in a sparse matrix and corpus vocabulary\n",
    "X, vocabulary, vocab_dict = btm.get_words_freqs(texts)\n",
    "tf = np.array(X.sum(axis=0)).ravel()\n",
    "# Vectorizing documents\n",
    "docs_vec = btm.get_vectorized_docs(texts, vocabulary)\n",
    "docs_lens = list(map(len, docs_vec))\n",
    "# Generating biterms\n",
    "biterms = btm.get_biterms(docs_vec)\n",
    "\n",
    "# INITIALIZING AND RUNNING MODEL\n",
    "model = btm.BTM(\n",
    "    X, vocabulary, seed=12321, T= 10, M=10, alpha=50/8, beta=0.01)\n",
    "model.fit(biterms, iterations=60)\n",
    "p_zd = model.transform(docs_vec)\n",
    "\n",
    "# METRICS\n",
    "perplexity = btm.perplexity(model.matrix_topics_words_, p_zd, X, 10)\n",
    "coherence = btm.coherence(model.matrix_topics_words_, X, M=10)\n",
    "# or\n",
    "perplexity = model.perplexity_\n",
    "coherence = model.coherence_\n",
    "\n",
    "# LABELS\n",
    "model.labels_\n",
    "# or\n",
    "btm.get_docs_top_topic(texts, model.matrix_docs_topics_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tmplot as tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7ee54897f94ef1be95b212e8b7003e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(HTML(value='<b>Select a topic</b>:'), Dropdown(options=((0, 0), (…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualsisation\n",
    "tmp.report(model=model, docs=texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "405ea56bf45ea199fac477ac372722b0c5ca4ba0ab21c322acc84a9de2bce2a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
