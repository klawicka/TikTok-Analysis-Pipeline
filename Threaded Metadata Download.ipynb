{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code adapted from https://github.com/dfreelon/pyktok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import browser_cookie3\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import pyktok as pyk\n",
    "import csv\n",
    "from time import sleep\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service as ChromeiumService #sic\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.core.utils import ChromeType\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "\n",
    "headers = {'Accept-Encoding': 'gzip, deflate, sdch',\n",
    "           'Accept-Language': 'en-US,en;q=0.8',\n",
    "           'Upgrade-Insecure-Requests': '1',\n",
    "           'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36',\n",
    "           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "           'Cache-Control': 'max-age=0',\n",
    "           'Connection': 'keep-alive'}\n",
    "cookies = browser_cookie3.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiktok_json(video_url,browser_name=None):\n",
    "    global cookies\n",
    "    for i in range(10):\n",
    "        if browser_name is not None:\n",
    "            cookies = getattr(browser_cookie3,browser_name)(domain_name='tiktok.com')\n",
    "        tt = requests.get(video_url,\n",
    "                        headers=headers,\n",
    "                        cookies=cookies,\n",
    "                        timeout=60)\n",
    "        soup = BeautifulSoup(tt.text, \"html.parser\")\n",
    "        tt_script = soup.find('script', attrs={'id':\"SIGI_STATE\"})\n",
    "        try:\n",
    "            tt_json = json.loads(tt_script.string)\n",
    "        except AttributeError:\n",
    "            print(\"The function encountered a downstream error and did not deliver any data, which happens periodically (not sure why). Please try again later.\")\n",
    "            continue\n",
    "        return tt_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_row(video_obj, date, user_id):\n",
    "    data_header = ['video_id',\n",
    "                   'video_timestamp',\n",
    "                   'video_duration',\n",
    "                   'video_locationcreated',\n",
    "                   'video_diggcount',\n",
    "                   'video_sharecount',\n",
    "                   'video_commentcount',\n",
    "                   'video_playcount',\n",
    "                   'video_description',\n",
    "                   'video_date',\n",
    "                   'vodeo_user_id',\n",
    "                   'music_id',\n",
    "                   'music_title',\n",
    "                   'author_username',\n",
    "                   'author_name']\n",
    "    data_list = []\n",
    "    data_list.append(video_obj['id'])\n",
    "    try:\n",
    "        ctime = video_obj['createTime']\n",
    "        data_list.append(datetime.fromtimestamp(int(ctime)).isoformat())\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['video']['duration'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['locationCreated'])\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['stats']['diggCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['stats']['shareCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['stats']['commentCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['stats']['playCount'])\n",
    "    except Exception:\n",
    "        data_list.append(np.nan)\n",
    "    try:\n",
    "        data_list.append(video_obj['desc'])\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(date)\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(user_id)\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['music']['id'])\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['music']['title'])\n",
    "    except Exception:\n",
    "        data_list.append('')\n",
    "\n",
    "    try:\n",
    "        data_list.append(video_obj['author']['uniqueId'])\n",
    "    except Exception:\n",
    "        try:\n",
    "            data_list.append(video_obj['author'])\n",
    "        except Exception:\n",
    "            data_list.append('')\n",
    "    try:\n",
    "        data_list.append(video_obj['author']['nickname'])\n",
    "    except Exception:\n",
    "        try:\n",
    "            data_list.append(video_obj['nickname'])\n",
    "        except Exception:\n",
    "            data_list.append('')\n",
    "\n",
    "\n",
    "    data_row = pd.DataFrame(dict(zip(data_header,data_list)),index=[0])\n",
    "    return data_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv_file(url,metadata_fn, date, user_id):\n",
    "    try:\n",
    "        tt_json = get_tiktok_json(url)\n",
    "        data_slot = tt_json['ItemModule'][list(tt_json['ItemModule'].keys())[0]]\n",
    "        data_row = generate_data_row(data_slot, date, user_id)\n",
    "    except Exception:\n",
    "        print(f\"{url} link failed\")\n",
    "    try:\n",
    "        data_row.loc[0,\"author_verified\"] = tt_json['UserModule']['users'][list(tt_json['UserModule']['users'].keys())[0]]['verified']\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        if os.path.exists(metadata_fn):\n",
    "            metadata = pd.read_csv(metadata_fn,keep_default_na=False)\n",
    "            combined_data = pd.concat([metadata,data_row])\n",
    "        else:\n",
    "            combined_data = data_row\n",
    "        combined_data.to_csv(metadata_fn,index=False)\n",
    "        print(\"Saved metadata for video\", url,\"to\",os.getcwd())\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that requests from my IP got blocked afte around 60,000 to 80,000 asks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "number_of_threads = 10\n",
    "input_data_per_thread = []\n",
    "\n",
    "for i in range(number_of_threads):\n",
    "    input_data_per_thread.append([])\n",
    "\n",
    "iter = 0\n",
    "for index, row in df.iterrows():\n",
    "    thread_id = iter % number_of_threads\n",
    "    input_data_per_thread[thread_id].append(row)\n",
    "    iter += 1\n",
    "\n",
    "def threaded_function(thread_id):\n",
    "    while len(input_data_per_thread[thread_id]) > 0:\n",
    "        row = input_data_per_thread[thread_id].pop(0)\n",
    "        url = row[\"Link\"]\n",
    "        date = row[\"Date\"]\n",
    "        user_id = row[\"ID\"] \n",
    "        make_csv_file(url, \"tiktok_browse_thread_output_\" + str(thread_id) + \".csv\", date, user_id)\n",
    "        print (f\"Thread {thread_id} has {len(input_data_per_thread[thread_id])} left\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(number_of_threads):\n",
    "        thread = Thread(target = threaded_function, args = (i, ))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    for i in range(number_of_threads):\n",
    "        threads[i].join()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "405ea56bf45ea199fac477ac372722b0c5ca4ba0ab21c322acc84a9de2bce2a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
